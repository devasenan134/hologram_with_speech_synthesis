{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepFake_AUDIO.ipynb","provenance":[{"file_id":"12DU9tTAdQApwNA5HZ_ROHvSkT6D9bjuR","timestamp":1646391580147}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"V0xH8XNEelKI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646391684804,"user_tz":-330,"elapsed":15848,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}},"outputId":"78730db9-aaf5-493e-a511-b4cb15e57b06"},"source":["# Cloning the repository\n","!git clone https://github.com/misbah4064/Real-Time-Voice-Cloning.git"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Real-Time-Voice-Cloning'...\n","remote: Enumerating objects: 2453, done.\u001b[K\n","remote: Total 2453 (delta 0), reused 0 (delta 0), pack-reused 2453\u001b[K\n","Receiving objects: 100% (2453/2453), 363.73 MiB | 26.09 MiB/s, done.\n","Resolving deltas: 100% (1354/1354), done.\n"]}]},{"cell_type":"code","metadata":{"id":"syA0yeyQeosa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646391751132,"user_tz":-330,"elapsed":346,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}},"outputId":"8d48ba40-d3c8-4e11-f971-a880b2752d60"},"source":["# Changing the current directory to the repository's directory\n","%cd Real-Time-Voice-Cloning/"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Real-Time-Voice-Cloning\n"]}]},{"cell_type":"code","metadata":{"id":"Cgn7dHe1e5It","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646391853371,"user_tz":-330,"elapsed":80183,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}},"outputId":"f1e0d8fb-5208-44b5-e1f5-0db150fdce7e"},"source":["# Installing the dependencies\n","!pip install -q -r requirements.txt\n","!apt-get install -qq libportaudio2"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 109.3 MB 54 kB/s \n","\u001b[K     |████████████████████████████████| 86 kB 4.6 MB/s \n","\u001b[K     |████████████████████████████████| 676 kB 41.1 MB/s \n","\u001b[K     |████████████████████████████████| 235 kB 44.2 MB/s \n","\u001b[K     |████████████████████████████████| 8.3 MB 30.4 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 35.6 MB/s \n","\u001b[K     |████████████████████████████████| 3.1 MB 33.9 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 5.8 MB/s \n","\u001b[K     |████████████████████████████████| 488 kB 44.0 MB/s \n","\u001b[K     |████████████████████████████████| 20.2 MB 54.8 MB/s \n","\u001b[K     |████████████████████████████████| 80 kB 8.0 MB/s \n","\u001b[K     |████████████████████████████████| 81 kB 8.4 MB/s \n","\u001b[K     |████████████████████████████████| 69 kB 6.6 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n","\u001b[K     |████████████████████████████████| 59.9 MB 95 kB/s \n","\u001b[K     |████████████████████████████████| 338 kB 42.2 MB/s \n","\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n","Selecting previously unselected package libportaudio2:amd64.\n","(Reading database ... 155320 files and directories currently installed.)\n","Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n","Unpacking libportaudio2:amd64 (19.6.0-1) ...\n","Setting up libportaudio2:amd64 (19.6.0-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"]}]},{"cell_type":"code","metadata":{"id":"wq6gAjdxe5x9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646391943016,"user_tz":-330,"elapsed":1022,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}},"outputId":"494c9d58-9f9e-43b3-8ea7-5abd8dd118e8"},"source":["# Downloading pretrained data and unzipping it\n","!gdown https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc\n","!unzip pretrained.zip"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Access denied with the following error:\n","\n"," \tCannot retrieve the public link of the file. You may need to change\n","\tthe permission to 'Anyone with the link', or have had many accesses. \n","\n","You may still be able to access the file from the browser:\n","\n","\t https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc \n","\n","unzip:  cannot find or open pretrained.zip, pretrained.zip.zip or pretrained.zip.ZIP.\n"]}]},{"cell_type":"code","metadata":{"id":"OOA_HDrke8fv","colab":{"base_uri":"https://localhost:8080/","height":851},"executionInfo":{"status":"error","timestamp":1646391870840,"user_tz":-330,"elapsed":16836,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}},"outputId":"0e5eec01-7060-4228-e3fe-619ae3fe6939"},"source":["# Initializing all the encoder libraries\n","from IPython.display import Audio\n","from IPython.utils import io\n","from synthesizer.inference import Synthesizer\n","from encoder import inference as encoder\n","from vocoder import inference as vocoder\n","from pathlib import Path\n","import numpy as np\n","import librosa\n","encoder_weights = Path(\"encoder/saved_models/pretrained.pt\")\n","vocoder_weights = Path(\"vocoder/saved_models/pretrained/pretrained.pt\")\n","syn_dir = Path(\"synthesizer/saved_models/logs-pretrained/taco_pretrained\")\n","encoder.load_model(encoder_weights)\n","synthesizer = Synthesizer(syn_dir)\n","vocoder.load_model(vocoder_weights)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/content/Real-Time-Voice-Cloning/encoder/audio.py:13: UserWarning: Unable to import 'webrtcvad'. This package enables noise removal and is recommended.\n","  warn(\"Unable to import 'webrtcvad'. This package enables noise removal and is recommended.\")\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-5e1a4e7fe1aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvocoder_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vocoder/saved_models/pretrained/pretrained.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msyn_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"synthesizer/saved_models/logs-pretrained/taco_pretrained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msynthesizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynthesizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocoder_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Real-Time-Voice-Cloning/encoder/inference.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(weights_fpath, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeakerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'encoder/saved_models/pretrained.pt'"]}]},{"cell_type":"code","metadata":{"id":"PEU1RADbwcaB","executionInfo":{"status":"aborted","timestamp":1646391870834,"user_tz":-330,"elapsed":13,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}}},"source":["# text = \"I am the best actor wrestler and a super star\"\n","# text = \"I am the best business man in the world\"\n","# text = \"I am the best body builder\"\n","text = \"Did you subscribe to the channel\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKyRu-9XgYlT","executionInfo":{"status":"aborted","timestamp":1646391870839,"user_tz":-330,"elapsed":18,"user":{"displayName":"Devasenan Murugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPxQpK2EVaFWOJjdfikK2MNWjKAFthQ12nw-bW_uQ=s64","userId":"15686758824548239314"}}},"source":["in_fpath = Path(\"trump10.wav\")\n","reprocessed_wav = encoder.preprocess_wav(in_fpath)\n","original_wav, sampling_rate = librosa.load(in_fpath)\n","preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n","embed = encoder.embed_utterance(preprocessed_wav)\n","with io.capture_output() as captured:\n","  specs = synthesizer.synthesize_spectrograms([text], [embed])\n","generated_wav = vocoder.infer_waveform(specs[0])\n","generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n","display(Audio(generated_wav, rate=synthesizer.sample_rate))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nps3KzWq2snA"},"source":["Follow this YouTube channel for more such tutorials,\n","Link : https://www.youtube.com/user/19daredevill"]}]}